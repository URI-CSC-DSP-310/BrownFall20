---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.12
    jupytext_version: 1.6.0
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---
# Class 6: Exploratory Data Analysis

## Warmup

```{code-cell} ipython3
topics = ['what is data science', 'jupyter', 'conditional','functions', 'lists', 'dictionaries','pandas' ]
topics
```

What happens when we index with `-1`?
```{code-cell} ipython3
topics[-1]
```
We get the last value.

Recall last class we used `:` to index `DataFrames` with `.loc`, we can do that with lists too:

```{code-cell} ipython3
topics[-2:]
```

## Announcements

- next assignment will go up today
- try  practingin throughout the week
- Check Brightspace for TA office hours


## Why Exploratory Data Analysis (EDA) before cleaning?

Typically a Data process looks like one of these figures:
+++

![dsprocess osem](https://miro.medium.com/max/1200/1*eE8DP4biqtaIK3aIy1S2zA.png)

![ds process roles](https://miro.medium.com/max/4360/1*PzzcJA-cwXQ8hwlpM4DwbA@2x.jpeg)

Data cleaning, which some of you asked about on Friday, would typically, *happen* before EDA, but it's hard to know what good data looks like, until you're used to manipulating it. Also, it's hard to check if data is good (and your cleaning worked) without some EDA.  So, I'm choosing to *teach* EDA first. We'll do data cleaning next, with these tools from EDA available as options for checking and determining what cleaning to do.

## EDA

````{margin}
```{note}
In class, we used `%load http://drsmb.co/310` to pull in the url for the data. [Load](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-load) is an ipython (ther kernel thta Jupyter uses) magic function.  It allows us to read in data from another place. I've set that short url to link to the download url for [this hackmd](https://hackmd.io/ue6vbZIEQRenmXclpVuXpA?edit) as markdown(plain text). That way I can paste things and you can pull them directly into your notebook. We'll use it like a shared copy-paste.  
```
````

```{code-cell} ipython3
# a version of the SAFI data with more columns
data_url = 'https://raw.githubusercontent.com/brownsarahm/python-socialsci-files/master/data/SAFI_full_shortname.csv'
```

As usual, we import `pandas`
```{code-cell} ipython3
import pandas as pd
```

and pull in the data.
```{code-cell} ipython3
safi_df = pd.read_csv(data_url)
safi_df.head(2)
```

Recall on Friday, we can use `describe` to see several common descriptive statistics
```{code-cell} ipython3
safi_df.describe()
```
Then we remember that this includes `key_id` as a variable tht we don't actually want to treat as a variable, it's an index. We can change that with `set_index` and we can do it in memory (without assignment) using the `inplace` keyword.

```{code-cell} ipython3
safi_df.set_index('key_id',inplace=True)
safi_df.describe()
```

```{admonition} Try it yourself!
You can use settings on `pd.read_csv` to set the index when the data is read in instead of doing this after the fact
```

We can also use the descriptive statistics on a single variable.

```{code-cell} ipython3
safi_df['years_farm'].describe()
```


Note however that this is not well formatted, that's because it's a `Series` instead of a DataFrame


```{code-cell} ipython3
type(safi_df['years_farm'].describe())
```

We can use `reset_index()` to make it back into a dataframe
```{code-cell} ipython3
safi_df['years_farm'].describe().reset_index()
```

And we can drop the added index:
```{code-cell} ipython3
safi_df['years_farm'].describe().reset_index().set_index('index')
```

```{note}
See that we can chain operations together. This is a helpful feature, but to be used with care.
[Pep8](https://www.python.org/dev/peps/pep-0008/#maximum-line-length), the style conventions for python, recommends no more than 79 characters per line. A [summary](https://development.robinwinslow.uk/2014/01/05/summary-of-python-code-style-conventions/) and [another summary](https://pybit.es/pep8.html)
```


We can also use individual summary statistics on `DataFrame` or `Series` objects
````{margin}
```{tip}
one column of a `pd.DataFrame` is a `pd.Series`
```
````

```{code-cell} ipython3
safi_df['no_membrs'].max()
```

## Split - Apply - Combine

A powerful tool in pandas (and data analysis in general) is the ability to apply functions to subsets of the data.

`````{margin}
````{note}
In class, we used the load magic again here to get this url. Then split the cell, changed the second one to markdown with the code for the image
````
````{tip}
To include an image in a notebook, use:
```
![alt text here](url/or/path/to/image)
```
in a markdown cell
````
`````

![split-apply-combine](https://jakevdp.github.io/PythonDataScienceHandbook/figures/03.08-split-apply-combine.png)

For example, we can get descriptive statistics per village

```{code-cell} ipython3
safi_df.groupby('village').describe()
```

We can also rearrange this into a more usable format than this very wide format:
```{code-cell} ipython3
safi_df.groupby('village').describe().unstack().reset_index()
```

This, however, gives some funny variable names, to fix that, we first save it to a variable.

```{code-cell} ipython3
village_summary_df = safi_df.groupby('village').describe().unstack().reset_index()
```

Now we can use the rename function
````{margin}
```{tip}
Rename is also one thing you might do in cleaning a dataset.
```
````

```{code-cell} ipython3

help(village_summary_df.rename)
```


Rename takes a dict-like or function that maps from what's there to what to change it to. We can either provide the mapper and an axis or pass the mapper as the columns parameter. The columns parameter makes it more human readable, and explicit what we're doing.

````{margin}
`inplace` again. See questions at the bottom for more on what it does
````

```{code-cell} ipython3
renaming_dict = {'level_0':'variable',
                'level_1':'statistic',
                0:'value'}
village_summary_df.rename(columns= renaming_dict,inplace=True)
```

Now we have a much better summary table. This is in what's called tidy format. Each colum

```{code-cell} ipython3
village_summary_df.head()
```

How could we use this to compute the average across villages for each statistic of each variable?

```{admonition} Try it yourself!
What would it look like to do this from the first result of `describe()` on the `groupby`, instead of with the `unstack` and `reset_index`?
```


We *do* need to `groupby` `'statistic'` and use `mean`, but that's not enough:
```{code-cell} ipython3
village_summary_df.groupby('statistic').mean()
```
This averages across all of the variables, too. So instead we need to groupby two variables.

```{code-cell} ipython3
village_summary_df.groupby(['statistic','variable']).mean()
```

```{code-cell} ipython3
safi_df.columns
```

What is the most common combination of `respondent_wall_type` and `respondent_floor_type`?

```{code-cell} ipython3
safi_df.groupby(['respondent_wall_type','respondent_floor_type'])['instanceID'].count().reset_index()
```

We can read this table to see the result. Or we might want it in a different way

```{code-cell} ipython3
safi_df.groupby(['respondent_wall_type','respondent_floor_type'])['instanceID'].count().unstack()
```

## Questions After Class

### What does the inplace parameter do?

We used inplace for the first time today right after we read in the data. Let's make a new DataFrame and compare what happens with and without.

````{margin}
```{tip}
I'm surprised I've remembered it repeatedly in class. I usually forget `inplace` don't get the output I want and then go back and add it. That's a normal part of programming.
```
````

```{code-cell} ipython3

safi_df_noinplace = pd.read_csv(data_url)
safi_df_inplace = pd.read_csv(data_url)
```

```{code-cell} ipython3
type(safi_df_noinplace.set_index('key_id'))
```

```{code-cell} ipython3
safi_df_noinplace.head()
```

```{code-cell} ipython3
type(safi_df_inplace.set_index('key_id',inplace=True))
```

```{code-cell} ipython3
safi_df_inplace.head()
```

Without `inplace`, `set_index` returns a dataframe, with the index changed, with `inplace` it returns `None`. But, without `inplace`, we don't see the desired effect when we do our next step, but with `inplace` the index is changed.  

Without the inplace, to save the changes you need to use an assignment. The following is equivalent to using `inplace`.

```{code-cell} ipython3
safi_df_noinplace= safi_df_noinplace.set_index('key_id'))
safi_df_noinplace.head()
```

### Why is a `for` loop slower than a `pandas` operation?

TL;DR: for this example, it's actually possible to relatively easily write a faster loop, but for other operations, it's unlikely.

Still, the pandas way is fewer lines, and can scale to larger datatypes quickly in ways we'll see later.

Basically, the advantage of using the library functions is that someone has already put a lot of though into the optimal way to implement things and it leverages core features of the data structure. Here is a [blog post](https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6) about iterating and applying functions in pandas.  It covers topics we haven't yet seen, but will.  



To test, we can do an experiment.  Let's take the last thing we covered in class today, finding the most common combination of floor and wall types.

First we'll look at two solutions and verify that they're the same.

First, how to do it with `pandas`

```{code-cell} ipython3
wall_floor_df = safi_df.groupby(['respondent_wall_type','respondent_floor_type'])['instanceID'].count()
wall_floor_df
```

We can read the answer off of that table, but let's get it programmatically:

```{code-cell} ipython3

wall_floor_df.idxmax()
```


Next, how to do it with a for loop (if you have a better for loop, make a PR so share it).
```{code-cell} ipython3
wall_floor_dict = {}

for wall,floor  in zip(safi_df['respondent_wall_type'],safi_df['respondent_floor_type']):
    wf_key = '_'.join([wall,floor])
    if wf_key in wall_floor_dict.keys():
        wall_floor_dict[wf_key] +=1
    else:
        wall_floor_dict[wf_key] =1

wall_floor_dict      
```
Again, we can read from the dict, but lets find it

```{code-cell} ipython3

max(wall_floor_dict, key=wall_floor_dict.get).split('_')
```



Now we can use a special feature of Jupyter notebooks to time them and see which is faster, called the [`%timeit`](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit) magic. Displaying visual things is always slow, so we'll take the line that would display out of both options.

````{margin}
```{tip}
This timing can be good when you have a large dataset, you can load a small part and and compare two ways of doing something you want to do with that. Then use only the faster on the whole dataset.

More detail on timing and profiling from the [text book](https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html)
```
````

Now timing the pandas way, with a human deciding
```{code-cell} ipython3
%%timeit -o

wall_floor_df = safi_df.groupby(['respondent_wall_type','respondent_floor_type'])['instanceID'].count().reset_index()
```

```{code-cell} ipython3
t_pandas = _
```
And capture the time by using the `_` it gets the std out from the previous cell.


For loop with required interpretation

```{code-cell} ipython3
%%timeit -o
wall_floor_dict = {}

for wall,floor  in zip(safi_df['respondent_wall_type'],safi_df['respondent_floor_type']):
    wf_key = '_'.join([wall,floor])
    if wf_key in wall_floor_dict.keys():
        wall_floor_dict[wf_key] +=1
    else:
        wall_floor_dict[wf_key] =1

max(wall_floor_dict, key=wall_floor_dict.get).split('_')

```

```{code-cell} ipython3
t_loop = _
```
On my local computer it was about 12x faster with that loop. Here, we'll calculate it for the GitHub servers that host the course manual.

````{margin}
```{tip}
You can also try it on your computer and see how it compares. Or try other loops/ways of doing it in pandas.
```
````

```{code-cell} ipython3

t_pandas.average/t_loop.average
```

Note, that the above was a relatively thoughtful attempt to make a fast loop.

```{code-cell} ipython3

%%timeit -o

wall_floor_dict = {}

for wall  in safi_df['respondent_wall_type']:
    for floor in safi_df['respondent_floor_type']:
        wf_key = '_'.join([wall,floor])
        if wf_key in wall_floor_dict.keys():
            wall_floor_dict[wf_key] +=1
        else:
            wall_floor_dict[wf_key] =1
```

```{code-cell} ipython3
t_loop_nozip = _
```

Using  `zip` (which we haven't talked about in class, but is a very handy [built in function](https://docs.python.org/3.3/library/functions.html#zip)) made it about 100x faster than using 2 for loops on my local machine.

```{code-cell} ipython3
t_loop_nozip.average/t_loop.average
```

Also the pandas version is about 8x faster locally (see below for GH server) than the nested loop version.

```{code-cell} ipython3
t_loop_nozip.average/t_pandas.average
```

For a more a complex question (say we wanted to know a statistic more complicated than the count) the loop gets harder (and probably slower), but the pandas operation stays about the same.


If you've made it this far, [let me know](https://forms.gle/PDATAmuRS5tAHiiZ8) how you found these notes. 
