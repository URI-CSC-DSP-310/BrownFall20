---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.12
    jupytext_version: 1.6.0
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Class 17: Evaluating Classification and Midsemester Feedback

1. share your favorite rainy day activity (or just say hi) in the zoom chat for attendance
1. log onto prismia

+++

<!-- annotate: Naive Bayes Review -->
## Naive Bayes Review


Main assumptions:
- classification assumes that features will separate the gorups
- NB:  conditionally independent

```{code-cell} ipython3
# %load http://drsmb.co/310
import pandas as pd
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
```

```{code-cell} ipython3
iris = sns.load_dataset("iris")
iris.head()
```

```{code-cell} ipython3
X_train, X_test, y_train, y_test = train_test_split(iris.values[:,:4],
                                                    iris.species.values,
                                                    test_size=0.5, random_state=0)
```

```{code-cell} ipython3
gnb = GaussianNB()
y_pred = gnb.fit(X_train, y_train).predict(X_test)
```

```{code-cell} ipython3
y_pred
```

```{code-cell} ipython3
y_test
```

```{code-cell} ipython3
sum(y_pred == y_test)
```

```{code-cell} ipython3
len(y_pred)
```

## Evaluating Classification


We can use the `score` method to compute accuracy by providing both features and target for the test set.
```{code-cell} ipython3
gnb.score(X_test, y_test)
```

Which is the same as the manual way we did before
```{code-cell} ipython3
sum(y_pred == y_test)/len(y_pred)
```

Scikit learn also provides a whole metrics module. We'll look at two functions from it today.

```{code-cell} ipython3
from sklearn.metrics import confusion_matrix, classification_report
```

First a Confusion matrix, which is the basic table of how the decisions were made. It counts how many from each true class were predicted to be in each class.  My favorite refernce on these is the table on the [wikipedia article](https://en.wikipedia.org/wiki/Confusion_matrix).

```{code-cell} ipython3
confusion_matrix(y_test,y_pred,)
```

We can see this makes sense from looking at the data.
```{code-cell} ipython3
sns.pairplot(data =iris, hue='species')
```

We can also get a formatted report that uses the confusion matrix to compute multiple metrics

```{code-cell} ipython3
print(classification_report(y_test,y_pred))
```

## Inspecting a classifier

We can serialize any python object to inspect it with `__dict__`

```{code-cell} ipython3
gnb.__dict__
```


It includes attributes `theta_` and `sigma_` these characterize the mean and the variance of each class. Naive Bayes is a generative classifier, since we're using the Guassian NB, it means it assumes that the data are Gaussian in each class. For a generative classifier, we can draw synthetic data from the model it learned.  We can use this to decide if what it learned makes sense by comparing it qualitatively (or statistically) to the real data.


```{code-cell} ipython3
# %load http://drsmb.co/310
gnb_df = pd.DataFrame(np.concatenate([np.random.multivariate_normal(mu, sig*np.eye(4),20)
                                  for mu, sig in zip(gnb.theta_,gnb.sigma_)]))
gnb_df['species'] = [ci for cl in [[c]*20 for c in gnb.classes_] for ci in cl]
sns.pairplot(data =gnb_df, hue='species')
```


## Feedback

Please complete this [feedback survey](https://forms.gle/yqWEPGJjFXDczuDv7) to provide input on how the semester is going for you so far.

## More practice

1. Try breaking down all the steps that are in the last cell one by one to understand them.
1. Read the documentation for naive bayes, how does it use the model parameters to make a prediction?
