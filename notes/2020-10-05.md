---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.12
    jupytext_version: 1.6.0
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Class 12: Constructing Datasets from Multiple Sources

```{code-cell} ipython3
import pandas as pd
```
## Introduction
Sometimes we use data from multiple sources. For example data may be provided across a bunch of tables and we want to put them together. Or we may want to build our own dataset to answer the questions that we want to ask.
For example we have a dataset of drivers who have been pulled over by the police, and need to compare distribution of them between day and night times. If we only have time of being pulled over without mentioning day/night, we can use another dataset including time of sunset for every day and build our own dataset out of these two dataset to find the answer.
Later we will also learn about getting data out of databses with some small database operations through SQLite and some python libararies.


To use relative paths as in class (`data/2018-games.csv`) instead of a full url `https://raw.githubusercontent.com/rhodyprog4ds/inclass-data/main/2018-games.csv`, download data from [this GitHub repo](https://github.com/rhodyprog4ds/inclass-data) by clicking on the green code button and choosing .zip. Then unzip the data and save it in a data folder in the same folder as the notebook. For the class notes, the urls make it so that the notebook can run without having to store the data in another place.


```{code-cell} ipython3
games_df18 = pd.read_csv('https://raw.githubusercontent.com/rhodyprog4ds/inclass-data/main/2018-games.csv')
games_df19 = pd.read_csv('https://raw.githubusercontent.com/rhodyprog4ds/inclass-data/main/2019-games.csv')
```

<!-- annotate: Stacking DataFrames -->
## Stacking DataFrames
Let's look at the first couple of rows to see how the configuration of data is.

```{code-cell} ipython3
games_df18.head(2)
```

```{code-cell} ipython3
games_df19.head(2)
```
As we can see, both datasets have the same columns, and just for two different years.
```{code-cell} ipython3
games_df18.shape
```

```{code-cell} ipython3
games_df19.shape
```
Let's concatenate two dataframes to make one dataframe out of them.
```{code-cell} ipython3
games_df = pd.concat([games_df18,games_df19])
games_df.shape
```
As we can see rows are added up but we have the same numbe of rcolums.

```{code-cell} ipython3
games_df.columns
```
Let's drop the column we do not need.
```{code-cell} ipython3
games_df.drop(columns= 'Unnamed: 0',inplace=True,)
games_df.head(2)
```

<!-- annotate: Merging Data Frames -->
## Merging Data Frames
Now we read another dataset which some of its columns are the same as dataframe "games_df" and some are different.
```{code-cell} ipython3
teams_df = pd.read_csv('https://raw.githubusercontent.com/rhodyprog4ds/inclass-data/main/teams.csv')
teams_df.head(2)
```
We use left_on='TEAM_ID' and right_on = 'HOME_TEAM_ID' to match two dataframes.
```{code-cell} ipython3
merge1_df = pd.merge(teams_df,games_df,left_on='TEAM_ID', right_on = 'HOME_TEAM_ID')
merge1_df.head(2)
```
We want information for each game and append the team info onto that. So, lets try another settings in our mergging.

```{code-cell} ipython3
merge1_df.shape
```

```{code-cell} ipython3
merge2_df = pd.merge(teams_df, games_df,left_on='TEAM_ID', right_on = 'HOME_TEAM_ID', how='outer')
```

```{code-cell} ipython3
merge2_df.head(2)
```

```{code-cell} ipython3
merge2_df.shape
```
We can group by "ARENA" and then look at the "mean" statistics.
```{code-cell} ipython3
merge1_df.groupby('ARENA').mean()
```


## How to combine the same data for different outcomes

We can combine datasets in different ways to learn different things about the data.
Let's now read info about the players.
```{code-cell} ipython3
players18 = pd.read_csv('https://raw.githubusercontent.com/rhodyprog4ds/inclass-data/main/2018-players.csv')
players19 = pd.read_csv('https://raw.githubusercontent.com/rhodyprog4ds/inclass-data/main/2019-players.csv')
players18.head()
```

First let's look at the shape of each of them to have a reference for what happens when we try different merges.

```{code-cell} ipython3
players18.shape, players19.shape
```

One thing we might want to do is to put all of the information into one long DataFrame. We can do this with `concat`.

```{code-cell} ipython3
pd.concat([players18,players19])
```
This allows us to see all the players for each year, we could do groupby and count to see how many players played each year for example.

We can check that this is the size we expected.

```{code-cell} ipython3
pd.concat([players18,players19]).shape
```

If we use the default merge settings we get an empty result because the two DataFrames have the same columns so pandas tries to merge `on` all of the columns, but there are no rows that have the same value in all of the columns, so there's nothing left.
```{code-cell} ipython3
pd.merge(players18,players19,)
```


If we merge with on='PLAYER_ID', it only requires that one column to be the same to match rows from the two DataFrames together.  With the default value for `how` or explicitly setting `how='inner'` we get the info of players who played both seasons.
```{code-cell} ipython3
pd.merge(players18,players19,on='PLAYER_ID', how='inner')
```

When we use outer we get one row for each player who played in either season or both seasons.  From this we can for example see who changed teams, who are the rookies in 2019 and who retired or was unsigned in 2019.
```{code-cell} ipython3
pd.merge(players18,players19,on='PLAYER_ID', how='outer')
```

If we use how='left' with `players18` as the left, we keep only the keys that are in the left DataFrame, so we can see who retired, but not the 2019 rookies.

```{code-cell} ipython3
pd.merge(players18,players19,on='PLAYER_ID', how='left')
```


## Try it yourself

Try different merges and inspect them:
- how many rows & columns?
- Where are NaN values inserted?
- What rows from the original datasets are not included?
- describe each type of merge in your own words


Split a DataFrame into separate data frames by subsetting the columns and indexing the rows with `loc`, then use concat to put it back together. Programmatically check that it's back together correctly.
