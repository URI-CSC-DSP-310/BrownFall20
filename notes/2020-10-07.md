---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.12
    jupytext_version: 1.6.0
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Class 13: Data from multiple sources and Databases


Welcome:

1. Say hello on zoom
1. Download data from Mondays' notes if you don't have it already
1. log onto Prismia.chat

```{code-cell} ipython3
import pandas as pd
```

<!-- annotate: Merging review -->
## Merging review

```{code-cell} ipython3
df18_players = pd.read_csv('data/2018-players.csv')
df19_players = pd.read_csv('data/2019-players.csv')
```

```{code-cell} ipython3
df18_players.shape, df19_players.shape
```

```{code-cell} ipython3
pd.merge(df18_players,df19_players,how='inner',on='PLAYER_ID')
```

```{code-cell} ipython3
pd.merge(df18_players,df19_players,how='outer',on='PLAYER_ID')
```

```{code-cell} ipython3
pd.merge(df18_players,df19_players,how='left',on='PLAYER_ID')
```

```{code-cell} ipython3
df18_games = pd.read_csv('data/2018-games.csv')
df19_games = pd.read_csv('data/2019-games.csv')
```

```{code-cell} ipython3
games_df = pd.concat([df18_games,df19_games])
games_df.head()
```


## Data

In order to work with large dataset, one option is to use a computer that has more memory, such as an HPC system. An easier option is to load data from a database instead of loading all data into memory. One way of working with databases is to use a Python library named `sqlite3` which allows us to create a connection between the database and Python so that we can pull data into Python to work with it.

```{warning}
To work with a database it needs to be downloaded, we can't load it via url like we did with the `.csv` files that we've been using, because when we need to make a connection to the database that can dynamically interact with the database.
```

Today, we'll work with a [database version](
https://datacarpentry.org/sql-socialsci/data/SQL_SAFI.sqlite) of the same SAFI dataset we've been working with. Download it and put it in a `data` folder that's in the same folder as your notebook.


First we'll import the needed library, this one doesn't have a standard alias, so we'll use it by referring to the whole name.

```{code-cell} ipython3
import sqlite3
```

First we'll connect to the database
```{code-cell} ipython3
con = sqlite3.connect('data/SQL_SAFI.sqlite')
```

Next we establish a cursor with the connection and then run a query.
```{code-cell} ipython3
cur = con.cursor()
cur.execute("SELECT * FROM Farms")
```
Here, "SELECT * FROM Farms" is a query we made into the cursor. It does not return the data, it just says what data to get ready, this is another opportunity to get the data in smaller chunks, we can choose in the next step to bring all or only some of the data from the query's result into Python.

This query says to get all (`*`) the data from the `Farms` table.

Now, we can use this cursor to pull all of the results from that query into our notebook.

```{code-cell} ipython3
rows = cur.fetchall()
rows
```
We can see it returns the data without much structure

```{code-cell} ipython3
type(rows)
```

and examine the type of one element of it as well.

```{code-cell} ipython3
type(rows[0])
```


we can also combine use of this library (to access databases) with `Pandas` functions to pull data from databases directly into a datagrame.  
```{code-cell} ipython3
df = pd.read_sql_query("SELECT * FROM Farms",con)

df.head()
```
This is the familiar SAFI data that we've been working with

## More Specific Queries

There are several ways that we can make our queries return only subsets of the data, this is where the database can start to provide real advantages, we can do sophisticated subsetting of our dataset in the database, which is optimized for performance at exactly these tasks, instead of in Python which is a general purpose programming language.

Strucutred Query Langauge  (SQL) is a powerful way of working with databases. We'll use it only through pandas going forward so that we can also use the nice visualizations from the notebook, but there are many other ways to use SQL.


For example we might only be interested in the location of the farms that were surveyed, so we can choose only those columns, by putting the column names in place of the `*` in the query.
```{code-cell} ipython3
location_df = pd.read_sql_query("SELECT Country, A06_Province, A07_district, A08_ward, A09_village FROM Farms",con)
location_df.head()
```

We can limit for the number of rows we get by using "LIMIT" keyword in the query.

```{code-cell} ipython3
pd.read_sql_query("SELECT * FROM Farms LIMIT 10",con)
```

```{admonition} Try it Yourself!
How would you return only the first 5 rows of the columns about food?

```{code-cell} ipython3
:tags:[hide-input]
food_df = pd.read_sql_query("SELECT G01_no_meals, G02_months_lack_food, G03_no_food_mitigation FROM Farms LIMIT 5",con)

food_df
```


We can use a "where" keyword to filter and only choose a subset of the rows conditionally, based on _values_ of the data. For example, we can look only at the farms that have living parents.

```{code-cell} ipython3
parents_df = pd.read_sql_query("SELECT Id, B17_parents_liv FROM Farms WHERE B17_parents_liv = 'yes'",con)
parents_df.head()
```


## Try it yourself

1. Write a queries to read from the database, the Id column and  two subsets of columns to 2 separate dataframes. Then use pandas to merge the dataframes into one.
1.
