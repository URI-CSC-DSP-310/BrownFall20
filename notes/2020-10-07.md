---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.12
    jupytext_version: 1.6.0
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Class 13: Data from mulitple sources and Databases 

Welcome:

1. Say hello on zoom
1. Download data from Mondays' notes if you dont have it already
1. log onto prismiaa

```{code-cell} ipython3
import pandas as pd
```

<!-- annotate: Merging review --> 
## Merging review

```{code-cell} ipython3
df18_players = pd.read_csv('data/2018-players.csv')
df19_players = pd.read_csv('data/2019-players.csv')
```

```{code-cell} ipython3
df18_players.shape, df19_players.shape
```

```{code-cell} ipython3
pd.merge(df18_players,df19_players,how='inner',on='PLAYER_ID')
```

```{code-cell} ipython3
pd.merge(df18_players,df19_players,how='outer',on='PLAYER_ID')
```

```{code-cell} ipython3
pd.merge(df18_players,df19_players,how='left',on='PLAYER_ID')
```

```{code-cell} ipython3
df18_games = pd.read_csv('data/2018-games.csv')
df19_games = pd.read_csv('data/2019-games.csv')
```

```{code-cell} ipython3
games_df = pd.concat([df18_games,df19_games])
games_df.head()
```

<!-- annotate: Data --> 
## Data

If we need to work with larger datasets, one option is working with larger computers. But another option is loading data from a database instead of loading all data to the memory(RAM). One way of working with databases is using a python library named "sqlite3" which allow us to creat a connection between database and Python.

**Database should be downloaded, because when we need to make a connection to the database and have a dynamic interaction with that. **

After downloading database,  there are three steps we need to take before working with data out of that:
1. Making conncetion between jupyter notebook (python environment), and database.
2. Running quiries on the database.
3. Getting the information out of database and work with that in Python.

**Importing library**
```{code-cell} ipython3
import sqlite3 
```

**Making the conncetion with the SQL_SAFI database**
```{code-cell} ipython3
con = sqlite3.connect('data/SQL_SAFI.sqlite')
```

**Creating Cursor**
```{code-cell} ipython3
cur = con.cursor()
cur.execute("SELECT * FROM Farms")
```
Here, "SELECT * FROM Farms" was a quiry we made into the cursor. It does not return the data, it just says we want the data from that.

Now, we can use this query to pull in the resluts to the python.

```{code-cell} ipython3
rows = cur.fetchall()
rows
```

```{code-cell} ipython3
type(rows)
```

```{code-cell} ipython3
type(rows[0])
```

```{code-cell} ipython3
df = pd.read_sql_query("SELECT * FROM Farms",con)
```

```{code-cell} ipython3
df.head()
```


we can also combine use of this library (to access databases) with Pandas' functions to pull data from databases to work with. We can also use Panda to add additional tables to the database.  

We can ask specidic information out of whole database. For example in the SAFI dataset if we need information with respect to location, we do as below.
```{code-cell} ipython3
location_df = pd.read_sql_query("SELECT Country, A06_Province, A07_district, A08_ward, A09_village FROM Farms",con)
location_df.head()
```
We can make a limit for the number of rows we are getting by using "LIMIT" keyword in the query. 
```{code-cell} ipython3
pd.read_sql_query("SELECT * FROM Farms LIMIT 10",con)
```

```{code-cell} ipython3
food_df = pd.read_sql_query("SELECT G01_no_meals, G02_months_lack_food, G03_no_food_mitigation FROM Farms LIMIT 5",con)



```

```{code-cell} ipython3
food_df
```
We can use a where keyword to filter and only choose a subset of rows on conditional basis, based on **values** of those rows.

```{code-cell} ipython3
parents_df = pd.read_sql_query("SELECT Id, B17_parents_liv FROM Farms WHERE B17_parents_liv = 'yes'",con)
parents_df.head()
```

```{code-cell} ipython3

```

```{code-cell} ipython3

```
