---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.12
    jupytext_version: 1.6.0
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Class 15: Intro to ML & Modeling


[handwritten notes from class](https://drive.google.com/file/d/1J3YYinBjJIBz4SD7wQ-kPG2_baGgWhHD/view)
+++

## What is a Model?

A model is a simplified representation of some part of the world. A famous quote about models is:


```{epigraph}
All models are wrong, but some are useful
--[George Box](https://en.wikipedia.org/wiki/All_models_are_wrong)[^wiki]
```

```{margin}
read more in the[Model Based Machine Learning Book](http://www.mbmlbook.com/LearningSkills_A_model_is_a_set_of_assumptions.html)
```

You might have seen models in chemistry class, for example about an atom:

<!-- ![bohrs model ]() -->

```{figure} https://upload.wikimedia.org/wikipedia/commons/a/a5/Bohr_atom_model_English.svg
---
height: 150px
name: bohrs
---
Brighterorange / [CC BY-SA](http://creativecommons.org/licenses/by-sa/3.0/)

```

An atom doesn't actually _look_ like this, but this is a _useful_ representation to help people learn how they function.  

In machine learning, we use models, that are generally _statistical_ models.



```{epigraph}
A statistical model is a mathematical model that embodies a set of statistical assumptions concerning the generation of sample data (and similar data from a larger population). A statistical model represents, often in considerably idealized form, the data-generating process

-- [wikipedia](https://en.wikipedia.org/wiki/Statistical_model#:~:text=A%20statistical%20model%20is%20a,%2C%20the%20data%2Dgenerating%20process.)
```


## Types of Models in Machine Learning

````{margin}
```{tip}
a common convention in mathematical notation is to denote matrices (tables) by capitalized bold characters , vectors (lists) by lowercase bold characters and scalars (single values) by lowercase regular characters.

For example:
- all of the features would be:  $\mathbf{X}$
- one variable for all samples or all variables for one sample would be $\mathbf{x}$
- one variable for one sample would be $x$
```
````

Starting from a dataset, we first make an additional designation about how we will use the different variables (columns). We will call most of them the _features_, which we denote mathematically with $\mathbf{X}$ and we'll choose one to be the _target_ or _labels_, denoted by $\mathbf{y}$.

The core assumption for just about all machine learning is that there exists some function $f$ so that for the $i$th sample

$$
  y_i = f(\mathbf{x}_i)
$$


Then with different additional assumptions we get different types of machine learning:
- if both features ($\mathbf{X}$) and target ($\mathbf{y}$) are observed (contained in our dataset) it's [__supervised learning__](https://en.wikipedia.org/wiki/Supervised_learning) [code](https://scikit-learn.org/stable/supervised_learning.html)
- if only the features ($\mathbf{X}$) are observed, it's [__unsupervised learning__](https://en.wikipedia.org/wiki/Unsupervised_learning) [code](https://scikit-learn.org/stable/unsupervised_learning.html)

There are more types, that we won't cover much in class but will mention here for completeness:
- if we have many samples for the features ($\mathbf{X}$) but only labels for some it's [__semi-supervised learning__](https://en.wikipedia.org/wiki/Semi-supervised_learning)
- if we have only features ($\mathbf{X}$) and an oracle (a person or some other labeler) that we can ask for labels from with a budget, so we can't get all of them, it's [_active learning)_](https://en.wikipedia.org/wiki/Active_learning_(machine_learning))
- [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning) involves taking actions and getting rewards.

## Supervised Learning

we'll focus on supervised learning first.  we can take that same core assumption and use it with additional information about our target variable to determine learning __task__ we are working to do.

$$
  y_i = f(\mathbf{x}_i)
$$

- if $y_i$ are discrete (eg flower species) we are doing __classification__
- if $y_i$ are continuous (eg height) we are doing __regression__


## Machine Learning Pipeline

To do machine learning we start with __training data__ which we put as input to the __learning algorithm__. A learning algorithm might be a generic optimization procedure or a specialized procedure for a specific model. The learning algorithm outputs a trained __model__ or the parameters of the model. When we deploy a model we pair the __fit model__ with a __prediction algorithm__ or __decision__ algorithm to evaluate a new sample in the world.

In experimenting and design, we need __testing data__ to evaluate how well our learning algorithm understood the world.  We need to use previously unseen data, because if we don't we can't tell if the prediction algorithm is using a rule that the learning algorithm produced or just looking up from a lookup table the result.  This can be thought of like the difference between memorization and understanding.

When the model does well on the training data, but not on test data, we say that it does not generalize well.  


## Try it yourself

1. List different machine learning applications you've interacted with and try to figure out what the features would be, what the target would be, and then what type of learning it is


## Glossary

```{tip}
This week we've learned a lot of new terms. Contribute definition below to form a glossary.
```

```{list-table}
:header-rows: 1

* - Term
  - Definition
* - Model
  - a mathematical representation of assumptions about the world

```
